{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "import baseline\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "class OptionalStandardScaler(StandardScaler): # class taken from transfer learning paper\n",
    "    def __init__(self, on=False):\n",
    "        super(OptionalStandardScaler, self).__init__(with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "audio = pickle.load( open( \"train_test_sets/train-1_test-1/audio.p\", \"rb\" ) )\n",
    "test_arousal_filenames = pickle.load( open( \"train_test_sets/train-1_test-1/test_arousal_filenames.p\", \"rb\" ) )\n",
    "test_arousal_audio, test_arousal_labels, dumby_doo_doo = util.split_set(test_arousal_filenames, 0.5, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = util.calcConvnetFeatures([test_arousal_audio[0]])\n",
    "# concat_test_features = [np.concatenate(np.array(l)) for l in feat]\n",
    "# pickle.dump(concat_test_features, open(\"train_test_sets/train-1_test-1/convnetTestConcatFeatures.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pickle.load( open( \"train_test_sets/train-1_test-1/convnetFeatures.p\", \"rb\" ) )\n",
    "pickle.dump(concat_features, open(\"train_test_sets/train-1_test-1/convnetConcatFeatures.p\", 'wb'))\n",
    "print np.array(features).shape\n",
    "print np.array(concat_features).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = baseline.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "predictions = b.clf.predict(b.test_arousal_mfcc)\n",
    "lw = 2\n",
    "plt.plot(np.array(range(len(predictions))), predictions, color='cornflowerblue', lw=lw, label='predictions')\n",
    "plt.plot(np.array(range(len(b.test_arousal_labels))), b.test_arousal_labels, color='darkorange', lw=lw, label='ground truth')\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('arousal')\n",
    "plt.title('Support Vector Regression for Arousal with MFCCs from 0.5 second audio')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print 'pearson correlation coefficient', (np.corrcoef(predictions, b.test_arousal_labels)[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import *\n",
    "train_valence_audio, dumby_doo_doo, train_valence_labels = split_set(b.train_valence_filenames, 0.5, b.audio)\n",
    "test_valence_audio, dumby_doo_doo, test_valence_labels = split_set(b.test_valence_filenames, 0.5, b.audio)\n",
    "valenceCLF = pickle.load( open( \"baseline_test_1_valence.sav\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = valenceCLF.predict(calcMFCCs(test_valence_audio))\n",
    "lw = 2\n",
    "plt.plot(np.array(range(len(predictions))), predictions, color='cornflowerblue', lw=lw, label='predictions')\n",
    "plt.plot(np.array(range(len(b.test_valence_labels))), b.test_valence_labels, color='darkorange', lw=lw, label='ground truth')\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('valence')\n",
    "plt.title('Support Vector Regression for Valence with MFCCs from 0.5 second audio')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print 'pearson correlation coefficient', (np.corrcoef(predictions, b.test_valence_labels)[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This JUST to generate the baseline models\n",
    "for i in [-1, 0, 1, 2, 3, 4, 5]:\n",
    "    train_valence_audio, dumby_doo_doo, train_valence_labels = split_set(b.train_valence_filenames, 2**i, b.audio)\n",
    "    test_valence_audio, dumby_doo_doo, test_valence_labels = split_set(b.test_valence_filenames, 2**i, b.audio)\n",
    "    train_arousal_audio, train_arousal_labels, dumby_doo_doo = split_set(b.train_arousal_filenames, 2**i, b.audio)\n",
    "    test_arousal_audio, test_arousal_labels, dumby_doo_doo = split_set(b.test_arousal_filenames, 2**i, b.audio)\n",
    "    length = 2**i\n",
    "    len_str = str(length) if length != 0.5 else 'half'\n",
    "    \n",
    "    arousal_filename = 'MODEL_arousal_mfcc_'+len_str+'_seconds.sav'\n",
    "    valence_filename = 'MODEL_valence_mfcc_'+len_str+'_seconds.sav'\n",
    "    b.train(train_arousal_labels, calcMFCCs(train_arousal_audio), arousal_filename)\n",
    "    b.train(train_valence_labels, calcMFCCs(train_valence_audio), valence_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This generates the convnet features - takes very long\n",
    "for i in [-1, 0, 1, 2, 3, 4, 5]:\n",
    "    length = 2**i\n",
    "    len_str = str(length) if length != 0.5 else 'half'\n",
    "    train_valence_audio, dumby_doo_doo, train_valence_labels = split_set(b.train_valence_filenames, 2**i, b.audio)\n",
    "    test_valence_audio, dumby_doo_doo, test_valence_labels = split_set(b.test_valence_filenames, 2**i, b.audio)\n",
    "    train_arousal_audio, train_arousal_labels, dumby_doo_doo = split_set(b.train_arousal_filenames, 2**i, b.audio)\n",
    "    test_arousal_audio, test_arousal_labels, dumby_doo_doo = split_set(b.test_arousal_filenames, 2**i, b.audio)\n",
    "    \n",
    "    train_arousal_convnet_features = calcConvnetFeatures(train_arousal_audio)\n",
    "    train_arousal_filename = 'FEATURES_TRAIN_arousal_convnet_'+len_str+'_seconds.sav'\n",
    "    pickle.dump(train_arousal_convnet_features, open(train_arousal_filename, 'wb'))\n",
    "    \n",
    "    train_valence_convnet_features = calcConvnetFeatures(train_valence_audio)\n",
    "    train_valence_filename = 'FEATURES_TRAIN_valence_convnet_'+len_str+'_seconds.sav'\n",
    "    pickle.dump(train_valence_convnet_features, open(train_valence_filename, 'wb'))\n",
    "    \n",
    "    test_arousal_convnet_features = calcConvnetFeatures(test_arousal_audio)\n",
    "    test_arousal_filename = 'FEATURES_TEST_arousal_convnet_'+len_str+'_seconds.sav'\n",
    "    pickle.dump(test_arousal_convnet_features, open(test_arousal_filename, 'wb'))\n",
    "    \n",
    "    test_valence_convnet_features = calcConvnetFeatures(test_valence_audio)\n",
    "    test_valence_filename = 'FEATURES_TEST_valence_convnet_'+len_str+'_seconds.sav'\n",
    "    pickle.dump(test_valence_convnet_features, open(test_valence_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This generates the convnet features for te validation set - takes long\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    length = 2**i\n",
    "    len_str = str(length) if length != 0.5 else 'half'\n",
    "    train_valence_audio, dumby_doo_doo, train_valence_labels = split_set(b.validate_train_valence_filenames, 2**i, b.validate_audio)\n",
    "    test_valence_audio, dumby_doo_doo, test_valence_labels = split_set(b.validate_test_valence_filenames, 2**i, b.validate_audio)\n",
    "    train_arousal_audio, train_arousal_labels, dumby_doo_doo = split_set(b.validate_train_arousal_filenames, 2**i, b.validate_audio)\n",
    "    test_arousal_audio, test_arousal_labels, dumby_doo_doo = split_set(b.validate_test_arousal_filenames, 2**i, b.validate_audio)\n",
    "    \n",
    "    train_arousal_convnet_features = calcConvnetFeatures(train_arousal_audio)\n",
    "    train_arousal_filename = 'FEATURES_TRAIN_arousal_convnet_'+len_str+'_seconds.sav'\n",
    "    pickle.dump(train_arousal_convnet_features, open(train_arousal_filename, 'wb'))\n",
    "    \n",
    "    train_valence_convnet_features = calcConvnetFeatures(train_valence_audio)\n",
    "    train_valence_filename = 'FEATURES_TRAIN_valence_convnet_'+len_str+'_seconds.sav'\n",
    "    pickle.dump(train_valence_convnet_features, open(train_valence_filename, 'wb'))\n",
    "    \n",
    "    test_arousal_convnet_features = calcConvnetFeatures(test_arousal_audio)\n",
    "    test_arousal_filename = 'FEATURES_TEST_arousal_convnet_'+len_str+'_seconds.sav'\n",
    "    pickle.dump(test_arousal_convnet_features, open(test_arousal_filename, 'wb'))\n",
    "    \n",
    "    test_valence_convnet_features = calcConvnetFeatures(test_valence_audio)\n",
    "    test_valence_filename = 'FEATURES_TEST_valence_convnet_'+len_str+'_seconds.sav'\n",
    "    pickle.dump(test_valence_convnet_features, open(test_valence_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This JUST to generate the convnet models\n",
    "for i in [-1, 0, 1, 2, 3, 4, 5]:\n",
    "    train_valence_audio, dumby_doo_doo, train_valence_labels = split_set(b.train_valence_filenames, 2**i, b.audio)\n",
    "    train_arousal_audio, train_arousal_labels, dumby_doo_doo = split_set(b.train_arousal_filenames, 2**i, b.audio)\n",
    "    \n",
    "    length = 2**i\n",
    "    len_str = str(length) if length != 0.5 else 'half'\n",
    "    \n",
    "    arousal_filename = 'MODEL_arousal_convnet_'+len_str+'_seconds.sav'\n",
    "    valence_filename = 'MODEL_valence_convnet_'+len_str+'_seconds.sav'\n",
    "    \n",
    "    train_arousal_convnet_features = pickle.load( open( \"convnet_features/FEATURES_TRAIN_arousal_convnet_\"+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "    train_valence_convnet_features = pickle.load( open( \"convnet_features/FEATURES_TRAIN_valence_convnet_\"+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "    \n",
    "    b.train(train_arousal_labels, train_arousal_convnet_features, arousal_filename)\n",
    "    b.train(train_valence_labels, train_valence_convnet_features, valence_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This JUST to generate the convnet models for validation set - takes long\n",
    "for i in [1, 2, 3, 4]:\n",
    "    train_valence_audio, dumby_doo_doo, train_valence_labels = split_set(b.validate_train_valence_filenames, 2**i, b.validate_audio)\n",
    "    train_arousal_audio, train_arousal_labels, dumby_doo_doo = split_set(b.validate_train_arousal_filenames, 2**i, b.validate_audio)\n",
    "    \n",
    "    length = 2**i\n",
    "    len_str = str(length) if length != 0.5 else 'half'\n",
    "    \n",
    "    arousal_filename = 'MODEL_arousal_convnet_'+len_str+'_seconds.sav'\n",
    "    valence_filename = 'MODEL_valence_convnet_'+len_str+'_seconds.sav'\n",
    "    \n",
    "    train_arousal_convnet_features = pickle.load( open( \"validate_convnet_features/FEATURES_TRAIN_arousal_convnet_\"+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "    train_valence_convnet_features = pickle.load( open( \"validate_convnet_features/FEATURES_TRAIN_valence_convnet_\"+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "    \n",
    "    b.train(train_arousal_labels, train_arousal_convnet_features, arousal_filename)\n",
    "    b.train(train_valence_labels, train_valence_convnet_features, valence_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results(length, label_type, modelType='mfcc'):\n",
    "    len_str = str(length) if length != 0.5 else 'half'\n",
    "    clf = None\n",
    "    test_audio = None\n",
    "    test_labels = None\n",
    "    if label_type == 'valence':\n",
    "        test_audio, dumby_doo_doo, test_labels = split_set(b.validate_test_valence_filenames, length, b.validate_audio)\n",
    "        clf = pickle.load( open( modelType+\"_models/MODEL_valence_\"+modelType+\"_\"+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "        train_filenames = b.train_valence_filenames\n",
    "    else:\n",
    "        test_audio, test_labels, dumby_doo_doo = split_set(b.validate_test_arousal_filenames, length, b.validate_audio)\n",
    "        clf = pickle.load( open( modelType+\"_models/MODEL_arousal_\"+modelType+\"_\"+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "        train_filenames = b.train_arousal_filenames\n",
    "    if modelType == 'mfcc':\n",
    "        feats = calcMFCCs(test_audio)\n",
    "        train_audio, dumby_doo_doo, train_labels = split_set(train_filenames, length, b.audio)\n",
    "        clf = clf.best_estimator_.fit(calcMFCCs(train_audio), train_labels)\n",
    "    else:\n",
    "        feats = pickle.load( open( \"validate_convnet_features/FEATURES_TEST_\"+label_type+\"_convnet_\"+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "        train_audio, dumby_doo_doo, train_labels = split_set(train_filenames, length, b.audio)\n",
    "        train_convnet_features = pickle.load( open( \"convnet_features/FEATURES_TRAIN_\"+label_type+\"_convnet_\"+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "        clf = clf.best_estimator_.fit(train_convnet_features, train_labels)\n",
    "    predictions = clf.predict(feats)\n",
    "    lw = 2\n",
    "    plt.plot(np.array(range(len(predictions))), predictions, color='cornflowerblue', lw=lw, label='predictions')\n",
    "    plt.plot(np.array(range(len(test_labels))), test_labels, color='darkorange', lw=lw, label='ground truth')\n",
    "    plt.xlabel('data')\n",
    "    plt.ylabel(label_type)\n",
    "    plt.title('Support Vector Regression for '+label_type+' with '+modelType+'\\'s from '+len_str+' second audio')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print 'r squared:', (np.corrcoef(predictions, test_labels)[0, 1] ** 2)\n",
    "    print 'r:', (np.corrcoef(predictions, test_labels)[0, 1])\n",
    "    print 'mse:', np.mean(((predictions - test_labels) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(.5, 'valence', 'mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(.5, 'arousal', 'mfcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "clf = pickle.load( open( \"convnet_test_1_arousal.sav\", \"rb\" ) )\n",
    "predictions = clf.predict(concat_test_features)\n",
    "lw = 2\n",
    "plt.plot(np.array(range(len(predictions))), predictions, color='cornflowerblue', lw=lw)\n",
    "plt.plot(np.array(range(len(test_arousal_labels))), test_arousal_labels, color='darkorange', lw=lw)\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('target')\n",
    "plt.title('Support Vector Regression with ConvNew Features from 0.5 second audio')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#file_names, audio, convnet_feature_prefix, convnet_model_prefix, mfcc_model_prefix\n",
    "data_info = {\n",
    "    \"valence_1_train\":\n",
    "    [b.train_valence_filenames, \n",
    "     b.audio,\n",
    "     \"convnet_features/FEATURES_TRAIN_valence_convnet_\",\n",
    "     \"convnet_models/MODEL_valence_convnet_\",\n",
    "     \"mfcc_models/MODEL_valence_mfcc_\"\n",
    "    ],\n",
    "    \"valence_1_test\":\n",
    "    [b.test_valence_filenames, \n",
    "     b.audio,\n",
    "     \"convnet_features/FEATURES_TEST_valence_convnet_\",\n",
    "     \"convnet_models/MODEL_valence_convnet_\",\n",
    "     \"mfcc_models/MODEL_valence_mfcc_\"\n",
    "    ],\n",
    "    \"valence_2_train\":\n",
    "    [b.validate_train_valence_filenames, \n",
    "     b.validate_audio,\n",
    "     \"validate_convnet_features/FEATURES_TRAIN_valence_convnet_\",\n",
    "     \"convnet_models/MODEL_valence_convnet_\",\n",
    "     \"mfcc_models/MODEL_valence_mfcc_\"\n",
    "    ],\n",
    "    \"valence_2_test\":\n",
    "    [b.validate_test_valence_filenames, \n",
    "     b.validate_audio,\n",
    "     \"validate_convnet_features/FEATURES_TEST_valence_convnet_\",\n",
    "     \"convnet_models/MODEL_valence_convnet_\",\n",
    "     \"mfcc_models/MODEL_valence_mfcc_\"\n",
    "    ],\n",
    "    \"arousal_1_train\":\n",
    "    [b.train_arousal_filenames, \n",
    "     b.audio,\n",
    "     \"convnet_features/FEATURES_TRAIN_arousal_convnet_\",\n",
    "     \"convnet_models/MODEL_arousal_convnet_\",\n",
    "     \"mfcc_models/MODEL_arousal_mfcc_\"\n",
    "    ],\n",
    "    \"arousal_1_test\":\n",
    "    [b.test_arousal_filenames, \n",
    "     b.audio,\n",
    "     \"convnet_features/FEATURES_TEST_arousal_convnet_\",\n",
    "     \"convnet_models/MODEL_arousal_convnet_\",\n",
    "     \"mfcc_models/MODEL_arousal_mfcc_\"\n",
    "    ],\n",
    "    \"arousal_2_train\":\n",
    "    [b.validate_train_arousal_filenames, \n",
    "     b.validate_audio,\n",
    "     \"validate_convnet_features/FEATURES_TRAIN_arousal_convnet_\",\n",
    "     \"convnet_models/MODEL_arousal_convnet_\",\n",
    "     \"mfcc_models/MODEL_arousal_mfcc_\"\n",
    "    ],\n",
    "    \"arousal_2_test\":\n",
    "    [b.validate_test_arousal_filenames, \n",
    "     b.validate_audio,\n",
    "     \"validate_convnet_features/FEATURES_TEST_arousal_convnet_\",\n",
    "     \"convnet_models/MODEL_arousal_convnet_\",\n",
    "     \"mfcc_models/MODEL_arousal_mfcc_\"\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns feat_names, candidate_svms, train_feature_vectors, test_feature_vectors,...\n",
    "#validate_feature_vectors, train_label_vectors, test_label_vectors, validate_label_vectors\n",
    "#can be this/other_2/1_train/test\n",
    "def prepare_multiple(\n",
    "    train_config=['this_1_train',], \n",
    "    test_config=['this_1_test'],\n",
    "    validate_config=['this_2_test'],\n",
    "    label_type=\"arousal\"):\n",
    "    \n",
    "    other_type = \"valence\" if label_type == \"arousal\" else \"arousal\"\n",
    "    train_set_config = [spec.replace(\"this\", label_type).replace(\"other\", other_type) for spec in train_config]\n",
    "    test_set_config = [spec.replace(\"this\", label_type).replace(\"other\", other_type) for spec in test_config]\n",
    "    validate_set_config = [spec.replace(\"this\", label_type).replace(\"other\", other_type) for spec in validate_config]\n",
    "    \n",
    "    feat_names = []\n",
    "    candidate_svms = []\n",
    "    train_feature_vectors = []\n",
    "    test_feature_vectors = []\n",
    "    validate_feature_vectors = []\n",
    "    train_label_vectors = []\n",
    "    test_label_vectors = []\n",
    "    validate_label_vectors = []\n",
    "    \n",
    "    for i in [-1, 0, 1, 2, 3, 4]:\n",
    "        length = 2**i\n",
    "        len_str = str(length) if length != 0.5 else 'half'\n",
    "        \n",
    "        print(\"processing \" + str(i) + \", will end at 4.\")\n",
    "        \n",
    "        #prepare train set\n",
    "        train_mfcc_features = []\n",
    "        train_convnet_features = []\n",
    "        train_labels = []\n",
    "        print \"\\t (1/3) preparing train set... \"\n",
    "        for train_model_spec in train_set_config:\n",
    "            [file_names, raw_audio, convnet_feature_prefix, convnet_model_prefix, mfcc_model_prefix] = data_info[train_model_spec]\n",
    "            split_audio, arousal_labels, valence_labels = split_set(file_names, 2**i, raw_audio)\n",
    "            labels = arousal_labels if label_type == \"arousal\" else valence_labels\n",
    "            if length >= 2:\n",
    "                convnet_features = pickle.load( open( convnet_feature_prefix+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "                train_convnet_features = train_convnet_features + convnet_features\n",
    "            mfcc_features = calcMFCCs(split_audio)\n",
    "            train_mfcc_features = train_mfcc_features + mfcc_features\n",
    "            train_labels = train_labels + labels\n",
    "        #prepare test set\n",
    "        test_mfcc_features = []\n",
    "        test_convnet_features = []\n",
    "        test_labels = []\n",
    "        print \"\\t (2/3) preparing test set... \"\n",
    "        for test_model_spec in test_set_config:\n",
    "            [file_names, raw_audio, convnet_feature_prefix, convnet_model_prefix, mfcc_model_prefix] = data_info[test_model_spec]\n",
    "            split_audio, arousal_labels, valence_labels = split_set(file_names, 2**i, raw_audio)\n",
    "            labels = arousal_labels if label_type == \"arousal\" else valence_labels\n",
    "            if length >= 2:\n",
    "                convnet_features = pickle.load( open( convnet_feature_prefix+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "                test_convnet_features = test_convnet_features + convnet_features\n",
    "            mfcc_features = calcMFCCs(split_audio)\n",
    "            test_mfcc_features = test_mfcc_features + mfcc_features\n",
    "            test_labels = test_labels + labels\n",
    "        #prepare validate set\n",
    "        validate_mfcc_features = []\n",
    "        validate_convnet_features = []\n",
    "        validate_labels = []\n",
    "        print \"\\t (3/3) preparing validate set... \"\n",
    "        for validate_model_spec in validate_set_config:\n",
    "            [file_names, raw_audio, convnet_feature_prefix, convnet_model_prefix, mfcc_model_prefix] = data_info[validate_model_spec]\n",
    "            split_audio, arousal_labels, valence_labels = split_set(file_names, 2**i, raw_audio)\n",
    "            labels = arousal_labels if label_type == \"arousal\" else valence_labels\n",
    "            if length >= 2:\n",
    "                convnet_features = pickle.load( open( convnet_feature_prefix+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "                validate_convnet_features = validate_convnet_features + convnet_features\n",
    "            mfcc_features = calcMFCCs(split_audio)\n",
    "            validate_mfcc_features = validate_mfcc_features + mfcc_features\n",
    "            validate_labels = validate_labels + labels\n",
    "            \n",
    "        if length >= 2:\n",
    "            convnet_clf = pickle.load( open( \"convnet_models/MODEL_\"+label_type+\"_convnet_\"+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "            candidate_svms.append(convnet_clf)\n",
    "            feat_names.append(\"convnet_\"+ len_str)\n",
    "            train_convnet_features, test_convnet_features, validate_convnet_features = norm_with_validate(\n",
    "                train_convnet_features, test_convnet_features, validate_convnet_features)\n",
    "            train_feature_vectors.append(train_convnet_features)\n",
    "            test_feature_vectors.append(test_convnet_features)\n",
    "            validate_feature_vectors.append(validate_convnet_features)\n",
    "            train_label_vectors.append(train_labels)\n",
    "            test_label_vectors.append(test_labels)\n",
    "            validate_label_vectors.append(validate_labels)\n",
    "            \n",
    "        mfcc_clf = pickle.load( open( \"mfcc_models/MODEL_\"+label_type+\"_mfcc_\"+len_str+\"_seconds.sav\", \"rb\" ) )\n",
    "        candidate_svms.append(mfcc_clf)\n",
    "        feat_names.append(\"mfcc_\"+ len_str)\n",
    "        train_mfcc_features, test_mfcc_features, validate_mfcc_features = norm_with_validate(\n",
    "                train_mfcc_features, test_mfcc_features, validate_mfcc_features)\n",
    "        train_feature_vectors.append(train_mfcc_features)\n",
    "        test_feature_vectors.append(test_mfcc_features)\n",
    "        validate_feature_vectors.append(validate_mfcc_features)\n",
    "        train_label_vectors.append(train_labels)\n",
    "        test_label_vectors.append(test_labels)\n",
    "        validate_label_vectors.append(validate_labels)\n",
    "    print \"DONE\"\n",
    "    return feat_names, candidate_svms, train_feature_vectors, test_feature_vectors, validate_feature_vectors, train_label_vectors, test_label_vectors, validate_label_vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names, candidate_svms, train_feature_vectors, test_feature_vectors, validate_feature_vectors, train_label_vectors, test_label_vectors, validate_label_vectors = prepare_multiple()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_feature_indexes, best_performance, best_svm = forward_select(candidate_svms, \n",
    "                                                                      train_feature_vectors, \n",
    "                                                                      train_label_vectors, \n",
    "                                                                      test_feature_vectors, \n",
    "                                                                      test_label_vectors, \n",
    "                                                                      \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[feat_names[idx] for idx in selected_feature_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_from_forward_selection(feat_indexes, model, label_type=\"arousal\"):\n",
    "    feature_vectors_validate = [validate_feature_vectors[i] for i in feat_indexes]\n",
    "    label_vectors_validate = [validate_label_vectors[i] for i in feat_indexes]\n",
    "    feature_vectors_validate, label_vectors_validate = trim(feature_vectors_validate, label_vectors_validate)\n",
    "    feature_vectors_train = [train_feature_vectors[i] for i in feat_indexes]\n",
    "    label_vectors_train = [train_label_vectors[i] for i in feat_indexes]\n",
    "    feature_vectors_train, label_vectors_train = trim(feature_vectors_train, label_vectors_train)\n",
    "    model.fit(feature_vectors_train, label_vectors_train)\n",
    "    predictions = model.predict(feature_vectors_validate)\n",
    "    lw = 2\n",
    "    plt.plot(np.array(range(len(predictions))), predictions, color='cornflowerblue', lw=lw, label='predictions')\n",
    "    plt.plot(np.array(range(len(label_vectors_validate))), label_vectors_validate, color='darkorange', lw=lw, label='ground truth')\n",
    "    plt.xlabel('data')\n",
    "    plt.ylabel(label_type)\n",
    "    plt.title('Support Vector Regression for '+label_type + ' with forward selection')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print 'r squared:', (np.corrcoef(predictions, label_vectors_validate)[0, 1] ** 2)\n",
    "    print 'r:', (np.corrcoef(predictions, label_vectors_validate)[0, 1])\n",
    "    print 'mse:', np.mean(((predictions - label_vectors_validate) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_from_forward_selection(selected_feature_indexes, best_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_without_flatten(feature_list, label_list):\n",
    "    feature_vector = []\n",
    "    label_vector = []\n",
    "\n",
    "    shortest_length = min([len(l) for l in label_list])\n",
    "    for l in label_list:\n",
    "        if len(l) == shortest_length:\n",
    "            label_vector = l\n",
    "\n",
    "    # For every feature in the shortest list, concatenate the\n",
    "    # appropriate feature from each list\n",
    "    for feature_index in range(len(feature_list)):\n",
    "        trimmed_list = []\n",
    "        curr_list = feature_list[feature_index]\n",
    "        \n",
    "        for list_index in range(shortest_length):\n",
    "            new_idx = ((list_index + 1) * int(len(curr_list) / shortest_length)) - 1\n",
    "            new_item = curr_list[new_idx]\n",
    "            trimmed_list.append(new_item)\n",
    "\n",
    "        feature_vector.append(trimmed_list)\n",
    "\n",
    "    return feature_vector, label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#expand\n",
    "def expand_with_delay(feature_list, label_list, names):\n",
    "    feature_vector = []\n",
    "    label_vector = []\n",
    "\n",
    "    label_vector = label_list[names.index('mfcc_half')]\n",
    "\n",
    "    for name in names:\n",
    "        current_feat = feature_list[names.index(name)]\n",
    "        split_name = name.split(\"_\")\n",
    "        feature_type = split_name[0]\n",
    "        length = 0.5 if split_name[1] == \"half\" else float(split_name[1])\n",
    "        num_to_remove = int((16.0 / length) - 1)\n",
    "        current_feat = current_feat[num_to_remove:]\n",
    "        duplicate_num = int(length / 0.5)\n",
    "        duplicated = []\n",
    "        for single_feat in current_feat:\n",
    "            for i in range(duplicate_num):\n",
    "                duplicated.append(single_feat)\n",
    "        duplicated = duplicated[4:] if feature_type == \"mfcc\" else duplicated[:-4]\n",
    "        feature_vector.append(duplicated)\n",
    "\n",
    "    label_vector = label_vector[32:] #get rid of beggining before longest prediction\n",
    "    label_vector = label_vector[4:] #get rid of 4 samples to simulate 2 second delay later\n",
    "    feature_vector = [feat[:len(label_vector)] for feat in feature_vector]\n",
    "    return feature_vector, label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for the multi-layer svr selection process\n",
    "trimmed_train_feat, trimmed_train_label = trim_without_flatten(train_feature_vectors, train_label_vectors)\n",
    "trimmed_test_feat, trimmed_test_label = trim_without_flatten(test_feature_vectors, test_label_vectors)\n",
    "trimmed_validate_feat, trimmed_validate_label = trim_without_flatten(validate_feature_vectors, validate_label_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data for the multi-layer svr selection process with delay to simulate real time operation\n",
    "trimmed_train_feat, trimmed_train_label = expand_with_delay(train_feature_vectors, train_label_vectors, feat_names)\n",
    "trimmed_test_feat, trimmed_test_label = expand_with_delay(test_feature_vectors, test_label_vectors, feat_names)\n",
    "trimmed_validate_feat, trimmed_validate_label = expand_with_delay(validate_feature_vectors, validate_label_vectors, feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_predictions = []\n",
    "all_test_predictions = []\n",
    "all_validate_predictions = []\n",
    "for i in range(len(trimmed_train_feat)):\n",
    "    model = candidate_svms[i]\n",
    "    model.best_estimator_.fit(trimmed_train_feat[i], trimmed_train_label)\n",
    "    train_predictions = model.predict(trimmed_train_feat[i])\n",
    "    test_predictions = model.predict(trimmed_test_feat[i])\n",
    "    validate_predictions = model.predict(trimmed_validate_feat[i])\n",
    "    all_train_predictions.append(train_predictions)\n",
    "    all_test_predictions.append(test_predictions)\n",
    "    all_validate_predictions.append(validate_predictions)\n",
    "best_hyper_model, input_models = backwardSelect(feat_names, all_train_predictions, trimmed_train_label, all_test_predictions, trimmed_test_label, \"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_indexes = [feat_names.index(item) for item in input_models]\n",
    "pred_vec = getPredictionVector(all_validate_predictions, input_indexes)\n",
    "predictions = best_hyper_model.predict(pred_vec)\n",
    "lw = 2\n",
    "plt.plot(np.array(range(len(predictions))), predictions, color='cornflowerblue', lw=lw, label='predictions')\n",
    "plt.plot(np.array(range(len(trimmed_validate_label))), trimmed_validate_label, color='darkorange', lw=lw, label='ground truth')\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('arousal')\n",
    "plt.title('Support Vector Regression for valence with backward selection')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print 'r squared:', (np.corrcoef(predictions, trimmed_validate_label)[0, 1] ** 2)\n",
    "print 'r:', (np.corrcoef(predictions, trimmed_validate_label)[0, 1])\n",
    "print 'mse:', np.mean(((predictions - trimmed_validate_label) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
